# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: "Build and Test Apache Flink"

on:
  workflow_call:
    inputs:
      stage_name:
        description: "defines a unique identifier for all jobs in a stage (in case the jobs are added multiple times to a stage)"
        required: true
        type: string
      environment:
        description: "defines environment variables for downstream scripts"
        required: true
        type: string
      jdk:
        description: "the jdk version to use"
        required: true
        type: number
      mode:
        description: "mode of execution. Can be nightly, e2e, release"
        required: true
        type: string
      run_end_to_end:
        description: "If set to 'true', the end to end tests will be executed"
        required: false
        default: false
        type: boolean
      e2e_group:
        description: "The group of e2e tests that should run"
        required: false
        type: number
    secrets:
      s3_bucket:
        required: true
      s3_access_key:
        required: true
      s3_secret_key:
        required: true
      glue_schema_access_key:
        required: true
      glue_schema_secret_key:
        required: true

env:
  FLINK_ARTIFACT_DIR: ${{ github.workspace }}/flink_artifacts
  MAVEN_REPOSITORY_DIR: ${{ github.workspace }}/.m2/repository
  DOCKER_IMAGES_CACHE_FOLDER: ${{ github.workspace }}/.docker-cache
  MAVEN_CACHE_FOLDER: ${{ github.workspace }}/.m2/repository
  E2E_CACHE_FOLDER: ${{ github.workspace }}/.e2e-cache
  E2E_TARBALL_CACHE: ${{ github.workspace }}/.e2e-tarbal-cache

jobs:
  compile:
    name: "Compile"
    runs-on: ubuntu-latest
    if: ${{ success() && inputs.mode != 'e2e' }}
    timeout-minutes: 240
    steps:
      - name: "Checks out Flink"
        uses: actions/checkout@v2

      - name: "Set up Maven" # and SSL???
        uses: stCarolas/setup-maven@v4.2
        with:
          maven-version: 3.2.5

      # The cache task is persisting the .m2 directory between builds, so that
      # we do not have to re-download all dependencies from maven central for
      # each build. The hope is that downloading the cache is faster than
      # all dependencies individually.
      # In this configuration, we use a hash over all committed (not generated) .pom files
      # as a key for the build cache (CACHE_KEY). If we have a cache miss on the hash
      # (usually because a pom file has changed), we'll fall back to a key without
      # the pom files (CACHE_FALLBACK_KEY).
      - name: "Cache Maven local repo"
        if: ${{ inputs.test_pool_name != 'Default' }}
        uses: actions/cache@v2
        with:
          path: ${{ env.MAVEN_REPOSITORY_DIR }}
          key: maven-${{ runner.os }}-${{ hashFiles('**/pom.xml', '!**/target/**') }}
          restore-keys: maven-${{ runner.os }}

      # see https://github.com/actions/setup-java#supported-distributions
      - name: "Set JDK ${{ inputs.jdk }}"
        uses: actions/setup-java@v2
        with:
          distribution: "temurin"
          java-version: ${{ inputs.jdk }}

      - name: "Compile Flink"
        env:
          MAVEN_OPTS: " -Dmaven.repo.local=${{ env.MAVEN_REPOSITORY_DIR }}"
        run: |
          ${{ inputs.environment }} ./tools/ci/compile.sh || exit $?

      - name: "Collect build artifacts"
        run: ./tools/azure-pipelines/create_build_artifact.sh -f ${{ env.FLINK_ARTIFACT_DIR }}

      # upload artifacts for next stage
      - name: Upload artifacts
        uses: actions/upload-artifact@v2
        with:
          name: FlinkCompileArtifact-${{ inputs.stage_name }}
          path: ${{ env.FLINK_ARTIFACT_DIR }}

  test:
    name: "Test (module: ${{ matrix.module }})"
    needs: compile
    runs-on: ubuntu-20.04
    if: ${{ success() && inputs.mode != 'e2e' }}
    strategy:
      matrix:
        module:
          - core
          - python
          - libraries
          - table
          - connectors
          - kafka/gelly
          - tests
          - misc
          - finegrained_resource_management

    steps:
      - name: "Flink Checkout"
        uses: actions/checkout@v2

      - name: "Set up Maven" # and SSL???
        uses: stCarolas/setup-maven@v4.2
        with:
          maven-version: 3.2.5

      # see https://github.com/actions/setup-java#supported-distributions
      - name: "Set JDK ${{ inputs.jdk }}"
        uses: actions/setup-java@v2
        with:
          distribution: "temurin"
          java-version: ${{ inputs.jdk }}

      # download artifact from compile stage
      - name: "Download pipeline artifact"
        uses: actions/download-artifact@v2
        with:
          name: FlinkCompileArtifact-${{ inputs.stage_name }}
          path: ${{ env.FLINK_ARTIFACT_DIR }}

      - name: "Unpack Build artifact"
        run: ./tools/azure-pipelines/unpack_build_artifact.sh -f ${{ env.FLINK_ARTIFACT_DIR }}

      - name: "Cache Maven local repo"
        if: ${{ inputs.test_pool_name != 'Default' }}
        uses: actions/cache@v2
        with:
          path: ${{ env.MAVEN_REPOSITORY_DIR }}
          key: maven-${{ runner.os }}-${{ hashFiles('**/pom.xml', '!**/target/**') }}
          restore-keys: maven-${{ runner.os }}

      - name: "Cache Docker images"
        id: docker-cache
        if: ${{ inputs.test_pool_name != 'Default' }}
        uses: actions/cache@v2
        with:
          path: ${{ env.DOCKER_IMAGES_CACHE_FOLDER }}
          key: ${{ matrix.module }}-docker-${{ runner.os }}-${{ hashFiles('**/cache_docker_images.sh', 'flink-test-utils-parent/**/DockerImageVersions.java') }}
          restore-keys: ${{ matrix.module }}-docker-${{ runner.os }}

      - name: "Load Docker images if not present in cache, yet"
        if: ${{ !cancelled() && !steps.docker-cache.cache.hit }}
        run: ./tools/azure-pipelines/cache_docker_images.sh -f ${{ env.DOCKER_IMAGES_CACHE_FOLDER }} load

      - name: "Set coredump pattern"
        run: sudo sysctl -w kernel.core_pattern=core.%p

      - name: "Test - ${{ matrix.module }}"
        id: test-run
        env:
          MAVEN_OPTS: " -Dmaven.repo.local=${{ env.MAVEN_REPOSITORY_DIR }}"
          IT_CASE_S3_BUCKET: ${{ secrets.s3_bucket }}
          IT_CASE_S3_ACCESS_KEY: ${{ secrets.s3_access_key }}
          IT_CASE_S3_SECRET_KEY: ${{ secrets.s3_secret_key }}
          IT_CASE_GLUE_SCHEMA_ACCESS_KEY: ${{ secrets.glue_schema_access_key }}
          IT_CASE_GLUE_SCHEMA_SECRET_KEY: ${{ secrets.glue_schema_secret_key }}
        timeout-minutes: 240
        run: |
          ${{ inputs.environment }} ./tools/azure-pipelines/uploading_watchdog.sh \
              -a ${{ github.job }} \
              -d ${{ runner.temp }} \
              -t 240 \
              ./tools/ci/test_controller.sh ${{ matrix.module }}

      - name: "Publish Unit Test Results"
        uses: EnricoMi/publish-unit-test-result-action@v1
        if: ${{ always() }}
        with:
          files: '**/TEST*.xml'

      - name: "Upload artifacts"
        uses: actions/upload-artifact@v2
        if: ${{ steps.test-run.outputs.debug-files-output-dir }} != ''
        with:
          name: logs-${{ inputs.stage_name }}-${{ steps.test-run.outputs.debug-files-name }}
          path: ${{ steps.test-run.outputs.debug-files-output-dir }}

      - name: "Save Docker images to cache"
        if: ${{ !cancelled() && (failure() || !steps.docker-cache.cache.hit) }}
        run: ./tools/azure-pipelines/cache_docker_images.sh -f ${{ env.DOCKER_IMAGES_CACHE_FOLDER }} save

#  e2e-prereq-check:
#    name: "Check: Doc-only PR"
#    runs-on: ubuntu-latest
#    if: ${{ inputs.run_end_to_end }}
#    steps:
#      # Skip e2e test execution if this is a documentation only pull request (master / release builds will still be checked regularly)
#      - name: "Check if it's a docs-only PR (i.e. e2e tests can be skipped)"
#        id: docs-only-pr-check
#        run: |
#          source ./tools/azure-pipelines/build_properties.sh
#          if is_docs_only_pullrequest; then
#            echo "This is a documentation-only change. Skipping e2e execution."
#            echo "::set-output name=skip-e2e::true"
#          else
#            echo "This is a regular CI build. Continuing ..."
#          fi
#
#  e2e-test:
#    name: "End to end tests"
#    runs-on: ubuntu-latest
#    needs: e2e-prereq-check
#    if: ${{ inputs.run_end_to_end && needs.e2e-prereq-check.outputs.skip-e2e != true }}
#    timeout-minutes: 310
#    steps:
#      - name: "Checks out Flink"
#        uses: actions/checkout@v
#
#      # the cache task does not create directories on a cache miss, and can later fail when trying to tar the directory if the test haven't created it
#      # this may for example happen if a given directory is only used by a subset of tests, which are run in a different 'group'
#      - name: "Create cache directories"
#        run: |
#          mkdir -p ${{ env.MAVEN_CACHE_FOLDER }}
#          mkdir -p ${{ env.E2E_CACHE_FOLDER }}
#          mkdir -p ${{ env.E2E_TARBALL_CACHE }}
#          mkdir -p ${{ env.DOCKER_IMAGES_CACHE_FOLDER }}
#
#      - name: "Cache Maven local repo"
#        uses: actions/cache@v2
#        with:
#          path: ${{ env.MAVEN_CACHE_FOLDER }}
#          key: maven-${{ runner.os }}-${{ hashFiles('**/pom.xml', '!**/target/**') }}
#          restoreKeys: maven-${{ runner.os }}
#
#      - name: "Cache E2E files"
#        uses: actions/cache@v2
#        with:
#          path: ${{ env.E2E_CACHE_FOLDER }}
#          key: e2e-cache-${{ inputs.group }}-${{ hashFiles('flink-end-to-end-tests/**/*.java', '!**/avro/**') }}
#
#      - name: "Cache E2E artifacts"
#        uses: actions/cache@v2
#        with:
#          path: ${{ env.E2E_TARBALL_CACHE }}
#          key: e2e-artifact-cache-${{ inputs.group }}-${{ hashFiles('flink-end-to-end-tests/**/*.sh') }}
#          restoreKeys: e2e-artifact-cache-${{ inputs.group }}
#
#      - name: "Cache Docker images"
#        id: docker-cache
#        uses: actions/cache@v2
#        with:
#          path: ${{ env.DOCKER_IMAGES_CACHE_FOLDER }}
#          key: e2e-${{ inputs.group }}-docker-${{ runner.os }}-${{ hashFiles('**/cache_docker_images.sh', 'flink-test-utils-parent/**/DockerImageVersions.java') }}
#
#      - name: "Load Docker images if not present in cache, yet"
#        if: ${{ !cancelled() && !steps.docker-cache.cache.hit }}
#        run: ./tools/azure-pipelines/cache_docker_images.sh -f ${{ env.DOCKER_IMAGES_CACHE_FOLDER }} load
#
#      # see https://github.com/actions/setup-java#supported-distributions
#      - name: "Set JDK ${{ inputs.jdk }}"
#        uses: actions/setup-java@v2
#        with:
#          distribution: "temurin"
#          java-version: ${{ inputs.jdk }}
#
#      - name: "Set up Maven" #and SSL??? This replaces the container from the original yml
#        uses: stCarolas/setup-maven@v4.2
#        with:
#          maven-version: 3.2.5
#
#      - name: "Install required dependencies bc and libapr1"
#        run: sudo apt-get install -y bc libapr1
#
#      - name: "Install libssl1.0.0 for netty tcnative"
#        run: |
#          wget http://security.ubuntu.com/ubuntu/pool/main/o/openssl1.0/libssl1.0.0_1.0.2n-1ubuntu5.7_amd64.deb
#          sudo apt install ./libssl1.0.0_1.0.2n-1ubuntu5.7_amd64.deb
#
#      - name: "Free up disk space"
#        run: ./tools/azure-pipelines/free_disk_space.sh
#
#      - name: "Build Flink"
#        run: ${{ inputs.environment }} PROFILE="$PROFILE -Dfast -Pskip-webui-build" ./tools/ci/compile.sh
#
#      - name: "Run E2E Tests"
#        id: test-run
#        env:
#          MAVEN_OPTS: " -Dmaven.repo.local=${{ env.MAVEN_REPOSITORY_DIR }}"
#          IT_CASE_S3_BUCKET: ${{ secrets.s3_bucket }}
#          IT_CASE_S3_ACCESS_KEY: ${{ secrets.s3_access_key }}
#          IT_CASE_S3_SECRET_KEY: ${{ secrets.s3_secret_key }}
#          IT_CASE_GLUE_SCHEMA_ACCESS_KEY: ${{ secrets.glue_schema_access_key }}
#          IT_CASE_GLUE_SCHEMA_SECRET_KEY: ${{ secrets.glue_schema_secret_key }}
#        timeout-minutes: 310
#        run: |
#          ${{ inputs.environment }} FLINK_DIR=`pwd`/build-target ./tools/azure-pipelines/uploading_watchdog.sh \
#            -a ${{ github.job }} \
#            -d ${{ runner.temp }} \
#            -t 310 \
#            flink-end-to-end-tests/run-nightly-tests.sh ${{ inputs.group }}
#
#      - name: "Upload Logs"
#        uses: actions/upload-artifact@v2
#        if: ${{ steps.test-run.outputs.debug-files-output-dir }} != ''
#        with:
#          name: logs-${{ inputs.stage_name }}-${{ steps.test-run.outputs.debug-files-name }}
#          path: ${{ steps.test-run.outputs.debug-files-output-dir }}
#
#      - name: "Save Docker images to cache"
#        if: ${{ !cancelled() && (failure() || !steps.docker-cache.cache.hit) }}
#        run: ./tools/azure-pipelines/cache_docker_images.sh -f ${{ env.DOCKER_IMAGES_CACHE_FOLDER }} save
